# OpenClaw Voice

**Open-source browser-based voice interface for AI assistants.**

Talk to your AI like you talk to Alexa â€” but self-hosted, private, and powered by your own agent.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-green.svg)

## Features

- ğŸ™ï¸ **Browser voice widget** â€” Push-to-talk or hands-free continuous mode
- ğŸš— **Continuous mode** â€” Auto-listens after each response. Perfect for hands-free use!
- ğŸ”Š **Local STT** â€” Whisper runs locally via faster-whisper. Your voice stays on your machine.
- ğŸ—£ï¸ **Premium TTS** â€” ElevenLabs for natural, expressive speech (Chatterbox available for self-hosted)
- ğŸ”Œ **Pluggable backend** â€” Connect to any AI (OpenAI, Claude, OpenClaw gateway, etc.)
- ğŸ¦ **OpenClaw integration** â€” Full agent context, memory, and tools via gateway
- ğŸŒ **WebSocket streaming** â€” Low latency audio over secure WebSockets
- ğŸ  **Fully self-hosted** â€” Your data stays on your servers

## Quick Start

### Prerequisites

- Python 3.10+
- ElevenLabs API key (recommended) or local TTS
- OpenAI API key (or OpenClaw gateway)

### Installation

```bash
# Clone the repo
git clone https://github.com/Purple-Horizons/openclaw-voice.git
cd openclaw-voice

# Create virtual environment
python -m venv .venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows

# Install dependencies
pip install -r requirements.txt

# Configure environment
cp .env.example .env
# Edit .env with your API keys

# Start the voice server
PYTHONPATH=. python -m src.server.main

# Open http://localhost:8765 in your browser
```

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    WebSocket     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Browser      â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  Voice Server   â”‚
â”‚  (Voice Widget) â”‚    Audio/Text    â”‚    (Python)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                         â”‚                         â”‚
              â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
              â”‚  Whisper  â”‚           â”‚   Your AI     â”‚         â”‚ ElevenLabs  â”‚
              â”‚   (STT)   â”‚           â”‚   Backend     â”‚         â”‚    (TTS)    â”‚
              â”‚  (local)  â”‚           â”‚               â”‚         â”‚             â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## OpenClaw Gateway Integration

For full agent capabilities (memory, tools, context), connect to OpenClaw's gateway:

```bash
# .env
OPENCLAW_GATEWAY_URL=http://localhost:18789
OPENCLAW_GATEWAY_TOKEN=your-gateway-token
ELEVENLABS_API_KEY=your-elevenlabs-key
```

Enable chatCompletions in your `openclaw.json`:

```json
{
  "gateway": {
    "http": {
      "endpoints": {
        "chatCompletions": { "enabled": true }
      }
    }
  },
  "agents": {
    "list": [{ "id": "voice", "workspace": "/your/workspace" }]
  }
}
```

Now voice chat routes through your full agent â€” same context as text chats.

## Configuration

```bash
# Via environment variables (.env)
OPENCLAW_STT_MODEL=base          # tiny, base, small, medium, large-v3-turbo
OPENCLAW_STT_DEVICE=auto         # auto, cpu, cuda, mps
OPENCLAW_PORT=8765
OPENCLAW_REQUIRE_AUTH=false      # Set true for production

# API Keys
ELEVENLABS_API_KEY=your-key      # For TTS (recommended)
OPENAI_API_KEY=your-key          # For AI backend (if not using gateway)

# OpenClaw Gateway (optional - for full agent integration)
OPENCLAW_GATEWAY_URL=http://localhost:18789
OPENCLAW_GATEWAY_TOKEN=your-token
```

## Supported Models

### Speech-to-Text (STT)
| Model | Speed | Quality | VRAM |
|-------|-------|---------|------|
| Whisper Large V3 Turbo | 216x realtime | Best | ~6GB |
| Whisper Base | Fast | Good | ~1GB |
| Whisper Tiny | Fastest | Fair | ~500MB |

### Text-to-Speech (TTS)
| Model | Type | Quality | Notes |
|-------|------|---------|-------|
| **ElevenLabs** | Cloud | Excellent | Recommended. Natural voices. |
| Chatterbox | Local | Very Good | MIT license, voice cloning |
| XTTS-v2 | Local | Excellent | Voice cloning supported |

## Browser Widget

The server includes a built-in web interface at the root URL.

For HTTPS (required for mobile microphone access), use:
- Tailscale Funnel
- nginx with SSL
- Cloudflare Tunnel

## API

### WebSocket Protocol

Connect to `ws://localhost:8765/ws` and send/receive JSON messages:

```javascript
// Start listening
{ "type": "start_listening" }

// Audio data (base64 PCM float32)
{ "type": "audio", "data": "base64..." }

// Stop listening
{ "type": "stop_listening" }

// Receive transcription
{ "type": "transcript", "text": "Hello world", "final": true }

// Receive AI response audio
{ "type": "audio_response", "data": "base64...", "text": "Hi there!" }
```

## Roadmap

- [x] Basic WebSocket voice gateway
- [x] Whisper STT integration
- [x] ElevenLabs TTS integration
- [x] Voice Activity Detection (VAD)
- [x] Streaming responses
- [x] Continuous conversation mode
- [x] API key authentication
- [ ] WebRTC for lower latency
- [ ] Voice cloning UI
- [ ] Docker support

## License

MIT License â€” see [LICENSE](LICENSE).

## Credits

- [faster-whisper](https://github.com/guillaumekln/faster-whisper) â€” CTranslate2 Whisper
- [ElevenLabs](https://elevenlabs.io) â€” Text-to-Speech
- [Silero VAD](https://github.com/snakers4/silero-vad) â€” Voice Activity Detection
- Built for [OpenClaw](https://openclaw.ai)

---

**Made with ğŸ¦ by [Purple Horizons](https://purplehorizons.io)**
